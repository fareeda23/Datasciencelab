import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Load the dataset
dataset = pd.read_csv('iris.csv')

# Display summary statistics and info
print(dataset.describe())
dataset.info()

# Define features and labels
X = dataset.iloc[:, [0, 1, 2, 3]].values
y = dataset.iloc[:, 4].values  # Correcting the column index for y (target variable)

# Split the dataset into training and test sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# Feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)

# Train a Logistic Regression classifier
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto')
classifier.fit(X_train, y_train)

# Predict the results
y_pred = classifier.predict(X_test)

# Predict probabilities for each class
probs_y = classifier.predict_proba(X_test)
probs_y = np.round(probs_y, 2)

# Format and display the results in a nice table
res = "{:<10}|{:<10}|{:<10}|{:<13}|{:<5}".format("y_test", "y_pred", "Setosa(%)", "Versicolor(%)", "Virginica(%)\n")
res += "-" * 65 + "\n"
res += "\n".join("{:<10}|{:<10}|{:<10}|{:<13}|{:<13}".format(x, y, a, b, c) 
                 for x, y, a, b, c in zip(y_test, y_pred, probs_y[:, 0], probs_y[:, 1], probs_y[:, 2]))
res += "\n" + "-" * 65 + "\n"
print(res)

# Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Visualize the confusion matrix using seaborn
import seaborn as sns

# Create a heatmap for the confusion matrix
ax = plt.axes()
df_cm = pd.DataFrame(cm, index=classifier.classes_, columns=classifier.classes_)
sns.heatmap(df_cm, annot=True, annot_kws={"size": 30}, fmt='d', cmap="Blues", ax=ax)

# Set the title and show the plot
ax.set_title('Confusion Matrix')
plt.show()
